{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zachery Moy_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacherymoy/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Zachery_Moy_DS_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer: Artificial neural networks are typically composed of input layers, hidden layers and output layers. The input layer is the very beginning of the workflow for the artificial neural network.\n",
        "\n",
        "\n",
        "### Hidden Layer: Artificial neural networks are typically composed of input layers, hidden layers and output layers. A hidden layer in an artificial neural network is a layer in between input layers and output layers, where artificial neurons take in a set of weighted inputs and produce an output through an activation function. It is a typical part of nearly any neural network in which engineers simulate the types of activity that go on in the human brain.\n",
        "\n",
        "\n",
        "### Output Layer: Artificial neural networks are typically composed of input layers, hidden layers and output layers. The output layer in an artificial neural network is the last layer of neurons that produces given outputs for the program.\n",
        "\n",
        "\n",
        "### Neuron: In this context, artificial neurons are similar to human nuerons. Programmers are inputting data for the computer to analyze. \n",
        "\n",
        "\n",
        "### Weight: Weights of a feature denote how much the feature matters in the model. This is a variable that can be used to better train your model. \n",
        "\n",
        "\n",
        "### Activation Function: Defines the output of that node given an input or set of inputs\n",
        "\n",
        "\n",
        "### Node Map: How nodes are then organized into layers to comprise a network.\n",
        "\n",
        "\n",
        "### Perceptron: The perceptron is an algorithm for supervised learning of binary classifiers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "A neural network is just a linear function with a non-linearity at the end, repeated over and over again.\n",
        "\n",
        "When you first input weights and biases will affect the inputs as you are training the model. These inputs are going through multiple layers such as through activation functions. The activation function is a mathematical “gate” in between the input feeding the current neuron and its output going to the next layer.\n",
        "\n",
        "At the end of the workflow is your output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKp5jnlWo1aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WrzFrqldidL",
        "colab_type": "code",
        "outputId": "0ee176bb-ec0c-49aa-98d0-a44b63679495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "weights = np.random.random((2,1))\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35090441],\n",
              "       [0.37065389]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJQ_khhp4ZjL",
        "colab_type": "code",
        "outputId": "a561910f-fe82-4eae-fb2f-296240cdaf2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "dfnp = df.to_numpy()\n",
        "dfnp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 1, 1],\n",
              "       [1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ytlddJQ4e9V",
        "colab_type": "code",
        "outputId": "21ead665-ae27-43d9-f485-17d3dc7f8f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "inputs = dfnp[:, 0:2]\n",
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6rZDYW-4izK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_outputs = dfnp[:, 2]\n",
        "correct_outputs = [[1],[1],[1],[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_eMrrOgd5Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNrBNn2yczfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputs = np.array([\n",
        "                  # [0,0,1],\n",
        "                  # [1,1,1],\n",
        "                  # [1,0,1],\n",
        "                  # [0,1,1]                   \n",
        "# \n",
        "# ])\n",
        "# \n",
        "# \n",
        "# correct_outputs = [[0], [1], [1], [0]]\n",
        "\n",
        "#is input the same as data? \n",
        "\n",
        "weights = 2 * np.random.random((4,2)) -1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Tyq-9yEGM8",
        "colab_type": "code",
        "outputId": "0a021590-ba74-4db5-a415-b782b2c4e8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs.shape, weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 2), (2, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYfdAqxydWFa",
        "colab_type": "code",
        "outputId": "876191ed-1bd5-44b8-e47a-0f7d7a073533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)\n",
        "weighted_sum"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.35090441],\n",
              "       [0.37065389],\n",
              "       [0.7215583 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs0SIRnYd2Zh",
        "colab_type": "code",
        "outputId": "9d57c4c3-b0ca-45c3-b608-d3c5ce749759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# activated value \n",
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.58683688],\n",
              "       [0.59161697],\n",
              "       [0.67295007]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y717zt0hDeZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59zGh6qvDbPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cac error\n",
        "error = correct_outputs - activated_output\n",
        "    \n",
        "adjustments = error * sigmoid_derivative(weighted_sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyasAr-y441f",
        "colab_type": "code",
        "outputId": "285e9310-8055-498d-87e8-d57514c64e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "weights += np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.30297126],\n",
              "       [0.3212134 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpVdaHbdDSQ7",
        "colab_type": "code",
        "outputId": "dff794b4-15d7-4e6a-c7aa-7bfe9e221269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Weights after training\")\n",
        "print(weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[0.30297126]\n",
            " [0.3212134 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFEHURKDIw_",
        "colab_type": "code",
        "outputId": "05114501-74ae-4468-8e24-0fc296d040bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output after training\n",
            "[[0.5       ]\n",
            " [0.58683688]\n",
            " [0.59161697]\n",
            " [0.67295007]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmInQIFehCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Left off the expected values. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPruSLrEo1av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate(inputs, weights, correct_ouputs):\n",
        "    \n",
        "    for iteration in range(10000):\n",
        "\n",
        "        # Weighted sum of inputs / weights\n",
        "        weighted_sum = np.dot(inputs, weights)\n",
        "        \n",
        "        activated_output = 1 / (1 + np.exp(-weighted_sum))\n",
        "\n",
        "        # Cac error\n",
        "        error = correct_outputs - activated_output\n",
        "        \n",
        "        sigmoid_derivative = activated_output * (1-activated_output)\n",
        "\n",
        "        adjustments = error * sigmoid_derivative\n",
        "\n",
        "        # Update the Weights\n",
        "        weights += np.dot(inputs.T, adjustments)\n",
        "\n",
        "    print(\"Weights after training\")\n",
        "    print(weights)\n",
        "\n",
        "    print(\"Output after training\")\n",
        "    print(activated_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNYAM0YL5E0a",
        "colab_type": "code",
        "outputId": "b3113aa9-8145-4281-e6d8-70d7db6bc6ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "calculate(inputs, weights, correct_outputs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-3.19189120e-16]\n",
            " [ 1.52655666e-16]]\n",
            "Output after training\n",
            "[[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuD_7bwLo1a_",
        "colab_type": "code",
        "outputId": "d4deae1f-d33c-44c5-da6e-b37c10599f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOSKur84ezXY",
        "colab_type": "code",
        "outputId": "8649a5d3-5c83-4fe1-8e91-b6bfe61378c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "n = Normalizer()\n",
        "\n",
        "X = diabetes[feats]\n",
        "Xn = n.fit_transform(X)\n",
        "y = np.array([[r] for r in diabetes['Outcome']])\n",
        "print(Xn[:5])\n",
        "y[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.03355237 0.82762513 0.40262844 0.19572216 0.         0.18789327\n",
            "  0.00350622 0.27960308]\n",
            " [0.008424   0.71604034 0.55598426 0.24429612 0.         0.22407851\n",
            "  0.00295683 0.26114412]\n",
            " [0.04039768 0.92409698 0.32318146 0.         0.         0.11765825\n",
            "  0.00339341 0.16159073]\n",
            " [0.00661199 0.58846737 0.43639153 0.15207584 0.62152733 0.185797\n",
            "  0.0011042  0.13885185]\n",
            " [0.         0.5963863  0.17412739 0.15236146 0.73133502 0.18762226\n",
            "  0.00996009 0.14365509]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjkreE9856Yr",
        "colab_type": "code",
        "outputId": "f9edaa5f-95a1-4132-cf01-a7441d3d97fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, rate = 0.01, niter = 10):\n",
        "        self.rate = rate\n",
        "        self.niter = niter\n",
        "    \n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        sx = sigmoid(x)\n",
        "        return sx * (1-sx)\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "\n",
        "        # Randomly Initialize Weights\n",
        "        self.weight = np.zeros(1 + X.shape[1])\n",
        "        self.errors = []\n",
        "        \n",
        "        for i in range(self.niter):\n",
        "          err = 0\n",
        "          for xi, target in zip(X, y):\n",
        "            delta_w = self.rate * (target - self.predict(xi))\n",
        "            self.weight[1:] += delta_w * xi\n",
        "            self.weight[0] += delta_w\n",
        "            err += int(delta_w != 0.0)\n",
        "          self.errors.append(err)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        \"\"\" Default Step Function\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
        "\n",
        "p = Perceptron()\n",
        "p.fit(Xn, y)\n",
        "print(p.predict(Xn)[:10])\n",
        "print(y[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1]\n",
            "[[1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gz-l77X-Yqf",
        "colab_type": "text"
      },
      "source": [
        "## What I've tried"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYFoJAaV57Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this = Perceptron()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WMBHoFH5_ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZM-CCjqe68N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code in class \n",
        "\n",
        "# y = df.iloc[0:100, 4].values\n",
        "# y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYXCT-_ZfAM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code in class \n",
        "\n",
        "# y = np.where(y == 'Iris-setosa', -1, 1)\n",
        "# y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE2lUw0qo1bS",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O21_za3Do1bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "\n",
        "X = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, niter = 10):\n",
        "        self.niter = niter\n",
        "    \n",
        "    def __sigmoid(self, x):\n",
        "        return None\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        return None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "    \"\"\"Fit training data\n",
        "    X : Training vectors, X.shape : [#samples, #features]\n",
        "    y : Target values, y.shape : [#samples]\n",
        "    \"\"\"\n",
        "\n",
        "        # Randomly Initialize Weights\n",
        "        weights = ...\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            # Weighted sum of inputs / weights\n",
        "\n",
        "            # Activate!\n",
        "\n",
        "            # Cac error\n",
        "\n",
        "            # Update the Weights\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "    \"\"\"Return class label after unit step\"\"\"\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xasncm-YfR_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code in class \n",
        "\n",
        "# class Perceptron(object):\n",
        "    \n",
        "#     def __init__(self, rate = 0.01, niter = 10):\n",
        "#         self.rate = rate\n",
        "#         self.niter = niter\n",
        "        \n",
        "#     def fit(self, X, y):\n",
        "#         \"\"\"Fit training data\n",
        "#         X : Training vectors, X.shape : [#samples, #features]\n",
        "#         y : Target values, y.shape : [#samples]\n",
        "#         \"\"\"\n",
        "\n",
        "#         # weights\n",
        "#         self.weight = np.zeros(1 + X.shape[1])\n",
        "\n",
        "#         # Number of misclassifications\n",
        "#         self.errors = []  # Number of misclassifications\n",
        "\n",
        "#         for i in range(self.niter):\n",
        "#           err = 0\n",
        "#           for xi, target in zip(X, y):\n",
        "#             delta_w = self.rate * (target - self.predict(xi))\n",
        "#             self.weight[1:] += delta_w * xi\n",
        "#             self.weight[0] += delta_w\n",
        "#             err += int(delta_w != 0.0)\n",
        "#           self.errors.append(err)\n",
        "#         return self\n",
        "\n",
        "#     def net_input(self, X):\n",
        "#         \"\"\"Calculate net input\"\"\"\n",
        "#         return np.dot(X, self.weight[1:]) + self.weight[0]\n",
        "\n",
        "#     def predict(self, X):\n",
        "#         \"\"\"Return class label after unit step\"\"\"\n",
        "#         \"\"\" Default Step Function\"\"\"\n",
        "#         return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJwEhQhKuNEa",
        "colab_type": "text"
      },
      "source": [
        "You backpropagate gradients by calculating partial derivatives with respect to each of our parameters and inputs. To do this, you use the chain rule.\n",
        "\n",
        "There's different types of activation functions and this reminds me of how people do pros and cons for algorithms. For example there's Rectified Linear Activation Function and Sigmoid activation functions. In general, your neural network will have two types of activation functions. The first will be the activation function used in hidden layers and the second will be used in the output layer. "
      ]
    }
  ]
}